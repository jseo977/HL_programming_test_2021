{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HeartLab_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x0zb9A0ART7N"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFI0FG12RIvW"
      },
      "source": [
        "# HeartLab Technical Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMcUJpddRkfr"
      },
      "source": [
        "This notebook outlines the process I underwent to create my CNN network which has approximately 90-92% validation accuracy.  \n",
        "Note that as this is a distributed public Google Colab notebook, the files need to be downloaded and uploaded into the files workspace in order to function like it would in a local IDE environment. During production, the notebook was used in a private workspace which had much faster file import times compared to what you will experience.  \n",
        "You may see this as substitute for the `main.py` script.  \n",
        "For best results, please run the cells in sequential order.  \n",
        "Please do reach out if there are any issues.  \n",
        "Best regards,  \n",
        "Jae Min ðŸŒ­"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjiFUv9FSi5f"
      },
      "source": [
        "#Prelims\n",
        "As we are running the code through Google Colab, we need to first upload files to allow this to work.\n",
        "Please download the files from this public Google Drive folder: https://drive.google.com/drive/folders/1uI856or3wqje2YwJeOLq0AkaDUMvQ9Vy?usp=sharing  \n",
        "You can upload them by dragging and dropping them onto the Files panel on the left (a runtime should be configured, and running on a (Google) GPU or TPU). Note that all files (`dataset.pickle`, `logs` (folder), `chest_xray` (folder), and `model.py`) should be unzipped, and found in the same directory as `'sample_data'`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vype_7uRLCP"
      },
      "source": [
        "# Imports and Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7NRE5wzgdY-"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Config and Inits\n",
        "#data_dir = \"drive/MyDrive/HeartLabTestFiles/chest_xray\"\n",
        "data_dir = \"chest_xray\"\n",
        "size = (256, 256)\n",
        "IMG_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0zb9A0ART7N"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-lMgF5VRViF"
      },
      "source": [
        "def img_2_arr(\n",
        "    img_path: str,\n",
        "    resize: bool = False,\n",
        "    grayscale: bool = True,\n",
        "    size: tuple = (256, 256),\n",
        ") -> np.ndarray:\n",
        "\n",
        "    \"\"\"\n",
        "    This function is responsible for opening an image, Preprocessing\n",
        "    it by color or size and returning a numpy array.\n",
        "\n",
        "    Input:\n",
        "        - img_path: str, a path to the location of a image file on disk\n",
        "        - resize: bool, True/False if the image is to be resized\n",
        "        - grayscale: bool, True/False if image is meant to be B&W or color\n",
        "        - size: tuple, a 2d tuple containing the x/y size of the image.\n",
        "\n",
        "    Output:\n",
        "        - a np.ndarray which is assosiated to the image that was input.\n",
        "    \"\"\"\n",
        "\n",
        "    if grayscale:\n",
        "        img_arr = cv2.imread(img_path, 0)\n",
        "    else:\n",
        "        img_arr = cv2.imread(img_path)\n",
        "\n",
        "    if resize:\n",
        "        img_arr = cv2.resize(img_arr, size)\n",
        "\n",
        "    return img_arr\n",
        "\n",
        "\n",
        "def create_datasets(data_dir: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    This function is responsible for creating a dataset which\n",
        "    contains all images and their associated class.\n",
        "\n",
        "    Inputs:\n",
        "        - data_dir: str, which is the location where the chest x-rays are\n",
        "            located.\n",
        "\n",
        "    Outputs:\n",
        "        - a np.ndarray which contains the processed image, and the class\n",
        "            int, associated with that class.\n",
        "\n",
        "    \"\"\"\n",
        "    # Image Loading and Preprocessing\n",
        "    all_normal_img_paths = []\n",
        "    all_viral_img_paths = []\n",
        "    all_bact_img_paths = []\n",
        "    for cls in os.listdir(data_dir): # NORMAL or PNEUMONIA\n",
        "        for img in os.listdir(os.path.join(data_dir, cls)): # all images\n",
        "            if cls == \"NORMAL\":\n",
        "                all_normal_img_paths.append(os.path.join(data_dir, cls, img))\n",
        "            elif \"virus\" in img:\n",
        "                all_viral_img_paths.append(os.path.join(data_dir, cls, img))\n",
        "            else:\n",
        "                all_bact_img_paths.append(os.path.join(data_dir, cls, img))\n",
        "\n",
        "    # 0 for normal, 1 for bacterial and 2 for viral\n",
        "    dataset = (\n",
        "        [\n",
        "            [img_2_arr(path, grayscale=True, resize=True, size=size), 0]\n",
        "            for path in all_normal_img_paths\n",
        "        ]\n",
        "        + [\n",
        "            [img_2_arr(path, grayscale=True, resize=True, size=size), 1]\n",
        "            for path in all_bact_img_paths\n",
        "        ]\n",
        "        + [\n",
        "            [img_2_arr(path, grayscale=True, resize=True, size=size), 2]\n",
        "            for path in all_viral_img_paths\n",
        "        ]\n",
        "    )\n",
        "    return np.array(dataset, dtype=\"object\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yqoq_z7RDd7"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCyBWunzleV8"
      },
      "source": [
        "# Retrieve data\n",
        "# Load the dataset.pickle data. If not found, the image data will be manually\n",
        "# processed again.\n",
        "try:\n",
        "    #with open('drive/MyDrive/HeartLabTestFiles/dataset.pickle', 'rb') as handle:\n",
        "    with open('dataset.pickle', 'rb') as handle:\n",
        "        dataset = pickle.load(handle)\n",
        "except:\n",
        "    dataset = create_datasets(data_dir)\n",
        "    with open('dataset.pickle', 'wb') as handle:\n",
        "        pickle.dump(dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TIqyPVaFE9"
      },
      "source": [
        "## Split Data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1srYHGLgTz_"
      },
      "source": [
        "# Split into training and testing sets\n",
        "images = [data[0] for data in dataset]\n",
        "labels = [data[1] for data in dataset]\n",
        "images_train, images_test,labels_train, labels_test = train_test_split(images, labels, test_size=0.2)\n",
        "images_train, images_test,labels_train, labels_test = np.array(images_train), np.array(images_test), np.array(labels_train), np.array(labels_test)\n",
        "images = np.array(images).reshape(len(images), IMG_SIZE, IMG_SIZE, 1)\n",
        "images_train = images_train.reshape(len(images_train), IMG_SIZE, IMG_SIZE, 1)\n",
        "images_test = images_test.reshape(len(images_test), IMG_SIZE, IMG_SIZE, 1)\n",
        "labels_train = tf.keras.utils.to_categorical(labels_train)\n",
        "labels_test = tf.keras.utils.to_categorical(labels_test)\n",
        "labels = tf.keras.utils.to_categorical(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMh5vLQKQyVJ"
      },
      "source": [
        "# Model Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7lJBNMNZREo"
      },
      "source": [
        "Would you like to run the Hyperparameter Optimisation algorithm?  \n",
        "This is not necessary, as I will demonstrate the optimised model at the end of the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcxbt2BAZPdi"
      },
      "source": [
        "run_hyper_param_opt = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL_gvNlnaAw6"
      },
      "source": [
        "## Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hBPLLj7gFx1"
      },
      "source": [
        "# Iteratively create a new model\n",
        "opt = ['agd', 'rmsprop', 'adam']\n",
        "loss = ['categorical_crossentropy', 'poisson']\n",
        "conv_layers = [1, 2, 3]\n",
        "dense_layers = [1, 2, 3 , 4, 5]\n",
        "layer_sizes = [32, 64, 128, 256]\n",
        "dropout = [0, 0.2, 0.4, 0.8]\n",
        "epochs = [10, 12, 15, 18, 20]\n",
        "\n",
        "# Set this to false by default as you will probably not want to train and test over 100\n",
        "# Convolutional Neural Networks\n",
        "if run_hyper_param_opt:\n",
        "  for dense_layer in dense_layers:\n",
        "      for layer_size in layer_sizes:\n",
        "          for drop in dropout:\n",
        "              for epoch in epochs:\n",
        "                name = \"10_Epoch_Single_No_Dropout_{}_nodes_{}_dense_{}_time\".format(drop, layer_size, dense_layer, int(time.time()))\n",
        "                tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
        "                print(name)\n",
        "                model = Sequential()\n",
        "                # Convolutional/Input Layer \n",
        "                model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(256,256,1)))\n",
        "                model.add(MaxPool2D(pool_size=(1,1)))\n",
        "                # flatten output of conv (input) layer \n",
        "                model.add(Flatten())\n",
        "\n",
        "                # Variable number of Dense Layers\n",
        "                for i in range(dense_layer):\n",
        "                    model.add(Dense(layer_size, activation='relu'))  \n",
        "                model.add(Dropout(drop))\n",
        "\n",
        "                # Final layer\n",
        "                model.add(Dense(layer_size, activation='relu'))\n",
        "\n",
        "                # output layer\n",
        "                model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "                # compiling the sequential model\n",
        "                model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "                model.fit(images_train, labels_train, epochs=epoch, batch_size=20, validation_data=(images_test,labels_test), callbacks = [tensorboard])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WauXvORDRfxe"
      },
      "source": [
        "# Analysing results with TensorBoard\n",
        "Ensure that the `'log'` folder has been uploaded into the files workspace on the left in order to view the TensorBoard with the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2sVFOZlkxDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "e40995c9-d591-4e1b-cf07-cc5784414d5c"
      },
      "source": [
        "%load_ext tensorboard\n",
        "!rm -rf ./logs/\n",
        "%tensorboard --logdir drive/MyDrive/HeartLabTestFiles/logs\n",
        "#%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elDmP2GLV8Lx"
      },
      "source": [
        "# The Selected Model\n",
        "The following model has been selected for its optimal output from the TensorBoard analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ4wJkbvWCDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e746d36-d41b-4122-c459-b4555d38442e"
      },
      "source": [
        "name = \"12_Epoch_Single_0.2_Dropout_256_nodes_3_dense_{}_time\".format(int(time.time()))\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
        "print(name)\n",
        "model_opt = Sequential()\n",
        "# Convolutional/Input Layer \n",
        "model_opt.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(256,256,1)))\n",
        "model_opt.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv (input) layer \n",
        "model_opt.add(Flatten())\n",
        "\n",
        "# Variable number of Dense Layers\n",
        "model_opt.add(Dense(256, activation='relu'))\n",
        "model_opt.add(Dense(256, activation='relu'))\n",
        "model_opt.add(Dropout(0.2))\n",
        "\n",
        "# Final layer\n",
        "model_opt.add(Dense(256, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model_opt.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model_opt.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "model_opt.fit(images_train, labels_train, epochs=15, batch_size=20, validation_data=(images_test,labels_test), callbacks = [tensorboard])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12_Epoch_Single_0.2_Dropout_256_nodes_3_dense_1629614446_time\n",
            "Epoch 1/15\n",
            "40/40 [==============================] - 43s 357ms/step - loss: 2548.9668 - accuracy: 0.4154 - val_loss: 167.7174 - val_accuracy: 0.5909\n",
            "Epoch 2/15\n",
            "40/40 [==============================] - 13s 323ms/step - loss: 79.0020 - accuracy: 0.6717 - val_loss: 16.2716 - val_accuracy: 0.8586\n",
            "Epoch 3/15\n",
            "40/40 [==============================] - 13s 319ms/step - loss: 16.5854 - accuracy: 0.8169 - val_loss: 10.5394 - val_accuracy: 0.8889\n",
            "Epoch 4/15\n",
            "40/40 [==============================] - 13s 318ms/step - loss: 4.8802 - accuracy: 0.9091 - val_loss: 8.7300 - val_accuracy: 0.8838\n",
            "Epoch 5/15\n",
            "40/40 [==============================] - 13s 320ms/step - loss: 2.0875 - accuracy: 0.9571 - val_loss: 10.4905 - val_accuracy: 0.8889\n",
            "Epoch 6/15\n",
            "40/40 [==============================] - 13s 324ms/step - loss: 2.5347 - accuracy: 0.9381 - val_loss: 8.1088 - val_accuracy: 0.8687\n",
            "Epoch 7/15\n",
            "40/40 [==============================] - 13s 323ms/step - loss: 0.7855 - accuracy: 0.9710 - val_loss: 8.6812 - val_accuracy: 0.8990\n",
            "Epoch 8/15\n",
            "40/40 [==============================] - 13s 319ms/step - loss: 0.6439 - accuracy: 0.9785 - val_loss: 9.7349 - val_accuracy: 0.8687\n",
            "Epoch 9/15\n",
            "40/40 [==============================] - 13s 321ms/step - loss: 0.4125 - accuracy: 0.9848 - val_loss: 7.6012 - val_accuracy: 0.8687\n",
            "Epoch 10/15\n",
            "40/40 [==============================] - 13s 320ms/step - loss: 0.5185 - accuracy: 0.9798 - val_loss: 6.4360 - val_accuracy: 0.8990\n",
            "Epoch 11/15\n",
            "40/40 [==============================] - 13s 321ms/step - loss: 0.2385 - accuracy: 0.9899 - val_loss: 7.9190 - val_accuracy: 0.8737\n",
            "Epoch 12/15\n",
            "40/40 [==============================] - 13s 325ms/step - loss: 0.2751 - accuracy: 0.9899 - val_loss: 6.0756 - val_accuracy: 0.8889\n",
            "Epoch 13/15\n",
            "40/40 [==============================] - 13s 326ms/step - loss: 0.0655 - accuracy: 0.9949 - val_loss: 11.1739 - val_accuracy: 0.8485\n",
            "Epoch 14/15\n",
            "40/40 [==============================] - 13s 321ms/step - loss: 0.1369 - accuracy: 0.9912 - val_loss: 7.1342 - val_accuracy: 0.8889\n",
            "Epoch 15/15\n",
            "40/40 [==============================] - 13s 320ms/step - loss: 0.1559 - accuracy: 0.9937 - val_loss: 7.9147 - val_accuracy: 0.9091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb3f05a690>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9s0skviWFCs"
      },
      "source": [
        "# Testing the Selected model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsfY6zQ1WHp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2831f4bc-50a9-4fba-a97b-190744abede2"
      },
      "source": [
        "model_opt.evaluate(images_test, labels_test)\n",
        "model_opt.evaluate(images, labels)\n",
        "# Save the model\n",
        "!mkdir -p saved_model\n",
        "model_opt.save('saved_model/model_opt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 61ms/step - loss: 7.9147 - accuracy: 0.9091\n",
            "31/31 [==============================] - 2s 57ms/step - loss: 1.5830 - accuracy: 0.9818\n",
            "INFO:tensorflow:Assets written to: saved_model/model_opt/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}